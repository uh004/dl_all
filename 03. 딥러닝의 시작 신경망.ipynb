{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장 퍼셉트론과 인공지능의 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 인공지능의 시작을 알린 퍼셉트론\n",
    "- 퍼셉트론(percepttron): 입력 값을 여러 개 받아 출력을 만드는데 이때 입력 값에 가중치를 조절할 수 있게 만들어 최초로 \"학습\"하게 됨\n",
    "- 아달라인(Adaline): 퍼셉트론에 경가 하강법을 도입해 최적의 경계선을 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론의 과제\n",
    "- 퍼셉트론이나 아달라인은 모두 2차원 평면상에 직선을 긋는 것만 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR 문제\n",
    "- AND 게이트: 입력값이 둘다 1일때 결과값 1 출력\n",
    "- OR 게이트: 둘중 하나라도 1이면 결과값 1 출력\n",
    "- XOR 게이트: 둘 중 하나만 1일때 결과값 1 출력\n",
    "- 이 문제는 두 가지 방법이 순차적으로 개발되면서 해결 1. 다층 퍼셉트론 2. 오차 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8장 다층 퍼센트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다층 퍼셉트론의 등장\n",
    "- 퍼셉트론 두 개를 한번에 계산 - 이를 위해 퍼셉트론 두 개를 각각 처리하는 은닉층을 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다층 퍼셉트론의 설계\n",
    "- x1과 x2는 입력 값인데 각 값에 가중치를 곱하고 바이어스를 통해 은닉층으로 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XOR 문제의 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 코딩으로 XOR 문제 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 가중치와 바이어스\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "w2 = np.array([1, 1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론\n",
    "def MLP(x, w, b):\n",
    "  y = np.sum(w * x) + b\n",
    "  if y <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAND 게이트\n",
    "def NAND(x1, x2):\n",
    "  return MLP(np.array([x1, x2]), w11, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR 게이트\n",
    "def OR(x1, x2):\n",
    "  return MLP(np.array([x1, x2]), w12, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND 게이트\n",
    "def AND(x1, x2):\n",
    "  return MLP(np.array([x1, x2]), w2, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR 게이트\n",
    "def XOR(x1, x2):\n",
    "  return AND(NAND(x1, x2), OR(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값: (0, 0)출력 값: 0\n",
      "입력 값: (1, 0)출력 값: 1\n",
      "입력 값: (0, 1)출력 값: 1\n",
      "입력 값: (1, 1)출력 값: 0\n"
     ]
    }
   ],
   "source": [
    "# x1 값, x2 값을 번갈아 대입하며 최종 값 출력\n",
    "for x in [(0,0), (1,0), (0,1), (1,1)]:\n",
    "  y = XOR(x[0], x[1])\n",
    "  print('입력 값: ' + str(x) + '출력 값: ' + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9장 오차 역전파에서 딥러닝으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 딥러닝의 태동 오차 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 활성화 함수와 고급 경사 하강법\n",
    "- 깊은 층을 만들어 보니 출력층에서 시작된 가중치 업데이트가 처음 층까지 전달되지 않는다. - 시그모이드 함수 특성(시그모이드 함수를 미분하면 최대치는 0.25이다. 1보다 작으므로 게속 곱하다 보면 0에 가까워져 여러 층을 겹칠수록 기울기가 사라짐)\n",
    "- 렐루 함수(ReLU): x가 0보다 작을 때 모든 값을 0, 0보다 큰 값은 x를 그대로 사용 - 오차 역전파 써도 처음까지 값이 남음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 속도와 정확도 문제를 해결하는 고급 경사 하강법\n",
    "1. 경사 하강법: 한 번 업데이트할 때마다 전체 데이터를 미분하므로 속도 느리고 최적 해를 찾기 전에 최적화 과정이 멈출 수 있다.\n",
    "2. 확률적 경사 하강법: 전체 데이터를 사용하는 것이 아니라 랜덤하게 추출한 일부 데이터만 사용하기 때문에 빠르고 더 자주 업데이트 가능\n",
    "3. 모멘텀(관성,탄력,가속도) 확률적 경사 하강법: 경사 하강법에 탄력을 더 해주는 것\n",
    "4. 아담(adam): 정확도와 속도를 모두 향상시킴"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
